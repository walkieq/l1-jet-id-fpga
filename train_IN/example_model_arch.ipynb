{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e58a653e-37e9-41e0-af8e-bf8a7067a7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Concatenate,\n",
    "    Flatten,\n",
    "    BatchNormalization,\n",
    "    Activation,\n",
    "    GlobalAveragePooling1D,\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from qkeras import QActivation, QDense, QConv1D, QConv2D, quantized_bits\n",
    "from qkeras.autoqkeras.utils import print_qmodel_summary\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n",
    "\n",
    "\n",
    "from node_edge_projection import NodeEdgeProjection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b9fd49d-0666-4fc5-9779-026af14c0f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "jetConstituent = np.load(\"data/jetConstituent_150_16f.npy\")\n",
    "target = np.load(\"data/jetConstituent_target_150_16f.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d97907d1-1b6a-4d9b-a50d-8fb38eb666e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict the number of constituents to a maximum of NMAX\n",
    "nmax = 30\n",
    "jetConstituent = jetConstituent[:, 0:nmax, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "727a000f-eee6-459e-b213-b6778de687f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jets = 260000\n",
      "Number of constituents = 30\n",
      "Number of features = 16\n"
     ]
    }
   ],
   "source": [
    "# The dataset is N_jets x N_constituents x N_features\n",
    "njet = jetConstituent.shape[0]\n",
    "nconstit = jetConstituent.shape[1]\n",
    "nfeat = jetConstituent.shape[2]\n",
    "\n",
    "\n",
    "print(\"Number of jets =\", njet)\n",
    "print(\"Number of constituents =\", nconstit)\n",
    "print(\"Number of features =\", nfeat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13c87a46-139b-4f2b-9802-42ccd2aab416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before --->> jetConstituent[0,0:4,0] =  [-177.97363281 -139.30709839 -122.01608276 -112.20430756]\n",
      "After --->> jetConstituent[0,0:4,0] =  [-82.26656342 -11.31220341 -36.57773209  -9.24982643]\n",
      "(174200, 30, 16) (85800, 30, 16) (174200, 5) (85800, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Shuffles jet constituents\n",
    "print(\"Before --->> jetConstituent[0,0:4,0] = \", jetConstituent[0, 0:4, 0])\n",
    "for i in range(jetConstituent.shape[0]):\n",
    "    jetConstituent[i] = jetConstituent[i, np.random.permutation(nconstit), :]\n",
    "print(\"After --->> jetConstituent[0,0:4,0] = \", jetConstituent[0, 0:4, 0])\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = jetConstituent\n",
    "Y = target\n",
    "del jetConstituent, target\n",
    "\n",
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.33, random_state=7\n",
    ")\n",
    "\n",
    "print(X_train_val.shape, X_test.shape, Y_train_val.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdb252dd-2a3a-4211-9f6b-eebb7c9ec912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of G jets for training/validation: 35213\n",
      "number of Q jets for training/validation: 33694\n",
      "number of W jets for training/validation: 35083\n",
      "number of Z jets for training/validation: 35023\n",
      "number of T jets for training/validation: 35187\n",
      "number of G jets for testing: 17191\n",
      "number of Q jets for testing: 16774\n",
      "number of W jets for testing: 17152\n",
      "number of Z jets for testing: 17275\n",
      "number of T jets for testing: 17408\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"number of G jets for training/validation: %i\"\n",
    "    % np.sum(np.argmax(Y_train_val, axis=1) == 0)\n",
    ")\n",
    "print(\n",
    "    \"number of Q jets for training/validation: %i\"\n",
    "    % np.sum(np.argmax(Y_train_val, axis=1) == 1)\n",
    ")\n",
    "print(\n",
    "    \"number of W jets for training/validation: %i\"\n",
    "    % np.sum(np.argmax(Y_train_val, axis=1) == 2)\n",
    ")\n",
    "print(\n",
    "    \"number of Z jets for training/validation: %i\"\n",
    "    % np.sum(np.argmax(Y_train_val, axis=1) == 3)\n",
    ")\n",
    "print(\n",
    "    \"number of T jets for training/validation: %i\"\n",
    "    % np.sum(np.argmax(Y_train_val, axis=1) == 4)\n",
    ")\n",
    "\n",
    "\n",
    "print(\"number of G jets for testing: %i\" % np.sum(np.argmax(Y_test, axis=1) == 0))\n",
    "print(\"number of Q jets for testing: %i\" % np.sum(np.argmax(Y_test, axis=1) == 1))\n",
    "print(\"number of W jets for testing: %i\" % np.sum(np.argmax(Y_test, axis=1) == 2))\n",
    "print(\"number of Z jets for testing: %i\" % np.sum(np.argmax(Y_test, axis=1) == 3))\n",
    "print(\"number of T jets for testing: %i\" % np.sum(np.argmax(Y_test, axis=1) == 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8414c59-4ff1-413a-8a50-5d3f366a1bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#jets =  174200\n",
      "#constituents =  30\n",
      "#targets =  5\n",
      "#features =  16\n"
     ]
    }
   ],
   "source": [
    "# baseline keras model\n",
    "\n",
    "njet = X_train_val.shape[0]\n",
    "nconstit = X_train_val.shape[1]\n",
    "ntargets = Y_train_val.shape[1]\n",
    "nfeat = X_train_val.shape[2]\n",
    "\n",
    "\n",
    "print(\"#jets = \", njet)\n",
    "print(\"#constituents = \", nconstit)\n",
    "print(\"#targets = \", ntargets)\n",
    "print(\"#features = \", nfeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3d9dbe6-60c2-46d4-bd49-ce330f9e17cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with max # of contituents =  30\n",
      "Number of node features =  16\n",
      "Quantization with nbits= 13\n",
      "Quantization of integer part= 2\n",
      "quantized_bits(13,2,0,alpha=1)\n"
     ]
    }
   ],
   "source": [
    "De = 8  # size of latent edges features representations\n",
    "Do = 6  # size of latent nodes features representations\n",
    "scale_e = 2  # multiplicative factor for # hidden neurons in Edges MLP\n",
    "scale_n = 2  # multiplicative factor for # hidden neurons in Nodes MLP\n",
    "scale_g = float(288/(Do))/(nmax*Do)\n",
    "NL = 0\n",
    "\n",
    "# Interaction Network model parameters\n",
    "N = nconstit\n",
    "P = nfeat\n",
    "Nr = N * (N - 1)  # number of relations ( edges )\n",
    "Dr = 0\n",
    "Dx = 0\n",
    "\n",
    "# Quantized bits\n",
    "nbits = 13\n",
    "integ = 2\n",
    "\n",
    "# Set QKeras quantizer and activation\n",
    "if nbits == 1:\n",
    "    qbits = \"binary(alpha=1)\"\n",
    "elif nbits == 2:\n",
    "    qbits = \"ternary(alpha=1)\"\n",
    "else:\n",
    "    qbits = \"quantized_bits({},{},0,alpha=1)\".format(nbits, integ)\n",
    "\n",
    "qact = \"quantized_relu({},{},0)\".format(nbits, integ)\n",
    "\n",
    "# Print\n",
    "print(\"Training with max # of contituents = \", nconstit)\n",
    "print(\"Number of node features = \", nfeat)\n",
    "print(\"Quantization with nbits=\", nbits)\n",
    "print(\"Quantization of integer part=\", integ)\n",
    "\n",
    "print(qbits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "607daac4-5b2f-4240-a3b3-de580626a5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input shape\n",
    "inp = Input(shape=(nconstit, nfeat), name=\"in_layer\")\n",
    "\n",
    "# Batch normalize the inputs\n",
    "x = BatchNormalization(name=\"batchnorm\")(inp)\n",
    "\n",
    "# Project to edges\n",
    "ORr = NodeEdgeProjection(name=\"proj_1\", receiving=True, node_to_edge=True)(x)\n",
    "ORs = NodeEdgeProjection(name=\"proj_2\", receiving=False, node_to_edge=True)(x)\n",
    "\n",
    "inp_e = Concatenate(axis=-1)(\n",
    "    [ORr, ORs]\n",
    ")  # Concatenates Or and Os  ( no relations features Ra matrix )\n",
    "\n",
    "# Edges MLP ( takes as inputs nodes features of a fully conected graph edges )\n",
    "\n",
    "# Define the Edges MLP layers\n",
    "nhidden_e = int((2 * P + Dr) * scale_e)\n",
    "if NL == 2:\n",
    "    h = QConv1D(\n",
    "        nhidden_e,\n",
    "        kernel_size=1,\n",
    "        kernel_quantizer=qbits,\n",
    "        bias_quantizer=qbits,\n",
    "        name=\"conv1D_e1\",\n",
    "    )(inp_e)\n",
    "    h = QActivation(qact, name=\"qrelu_e1\")(h)\n",
    "    h = QConv1D(\n",
    "        int(nhidden_e / 2),\n",
    "        kernel_size=1,\n",
    "        kernel_quantizer=qbits,\n",
    "        bias_quantizer=qbits,\n",
    "        name=\"conv1D_e2\",\n",
    "    )(h)\n",
    "    h = QActivation(qact, name=\"qrelu_e2\")(h)\n",
    "    h = QConv1D(\n",
    "        De,\n",
    "        kernel_size=1,\n",
    "        kernel_quantizer=qbits,\n",
    "        bias_quantizer=qbits,\n",
    "        name=\"conv1D_e3\",\n",
    "    )(h)\n",
    "if NL == 1:\n",
    "    h = QConv1D(\n",
    "        nhidden_e,\n",
    "        kernel_size=1,\n",
    "        kernel_quantizer=qbits,\n",
    "        bias_quantizer=qbits,\n",
    "        name=\"conv1D_e1\",\n",
    "    )(inp_e)\n",
    "    h = QActivation(qact, name=\"qrelu_e1\")(h)\n",
    "    h = QConv1D(\n",
    "        De,\n",
    "        kernel_size=1,\n",
    "        kernel_quantizer=qbits,\n",
    "        bias_quantizer=qbits,\n",
    "        name=\"conv1D_e3\",\n",
    "    )(h)\n",
    "elif NL == 0:\n",
    "    h = QConv1D(\n",
    "        De,\n",
    "        kernel_size=1,\n",
    "        kernel_quantizer=qbits,\n",
    "        bias_quantizer=qbits,\n",
    "        name=\"conv1D_e3\",\n",
    "    )(inp_e)\n",
    "\n",
    "out_e = QActivation(qact, name=\"qrelu_e3\")(h)\n",
    "\n",
    "# Project to nodes\n",
    "out_e = NodeEdgeProjection(name=\"proj_3\", receiving=True, node_to_edge=False)(out_e)\n",
    "\n",
    "# Nodes MLP ( takes as inputs node features and embeding from edges MLP )\n",
    "\n",
    "# Concatenate input Node features and Edges MLP output for the Nodes MLP input\n",
    "inp_n = Concatenate(axis=-1)(\n",
    "    [x, out_e]\n",
    ")  #  Original IN was C = tf.concat([N,x,E], axis=1)\n",
    "\n",
    "# Define the Nodes MLP layers\n",
    "nhidden_n = int((P + Dx + De) * scale_n)  # number of neurons in Nodes MLP hidden layer\n",
    "h = QConv1D(\n",
    "    nhidden_n,\n",
    "    kernel_size=1,\n",
    "    kernel_quantizer=qbits,\n",
    "    bias_quantizer=qbits,\n",
    "    name=\"conv1D_n1\",\n",
    ")(inp_n)\n",
    "h = QActivation(qact, name=\"qrelu_n1\")(h)\n",
    "h = QConv1D(\n",
    "    int(nhidden_n),\n",
    "    kernel_size=1,\n",
    "    kernel_quantizer=qbits,\n",
    "    bias_quantizer=qbits,\n",
    "    name=\"conv1D_n2\",\n",
    ")(h)\n",
    "h = QActivation(qact, name=\"qrelu_n2\")(h)\n",
    "h = QConv1D(\n",
    "    Do, kernel_size=1, kernel_quantizer=qbits, bias_quantizer=qbits, name=\"conv1D_n3\"\n",
    ")(h)\n",
    "out_n = QActivation(qact, name=\"qrelu_n3\")(h)\n",
    "\n",
    "#  Graph classification MLP\n",
    "\n",
    "# Flatten input for the Graph classifier MLP\n",
    "# inp_g = Flatten()(out_n)\n",
    "\n",
    "# Invariant operation\n",
    "out_n = QActivation(quantized_bits(bits=12, integer=3, symmetric=0, keep_negative=1))(out_n)\n",
    "inp_g = GlobalAveragePooling1D(name=\"pi_gp\")(out_n)\n",
    "\n",
    "\n",
    "# Define Graph classifier MLP  layers\n",
    "#nhidden_g = int((Do * N) * scale_g)  # Number of nodes in graph MLP hidden layer\n",
    "nhidden_g = int((Do * N) * scale_g)  # Number of nodes in graph MLP hidden layer\n",
    "\n",
    "h = QDense(nhidden_g, kernel_quantizer=qbits, bias_quantizer=qbits, name=\"dense_g1\")(inp_g)\n",
    "h = QActivation(qact, name=\"qrelu_g1\")(h)\n",
    "\n",
    "h = QDense(nhidden_g, kernel_quantizer=qbits, bias_quantizer=qbits, name=\"dense_g2\")(h)\n",
    "h = QActivation(qact, name=\"qrelu_g2\")(h)\n",
    "\n",
    "h = QDense(ntargets, kernel_quantizer=qbits, bias_quantizer=qbits, name=\"dense_out\")(h)\n",
    "out = Activation(\"softmax\", name=\"softmax_out\")(h)\n",
    "\n",
    "# create the model\n",
    "model = Model(inputs=inp, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "50362146-b0b6-4328-93e0-59e476b1e4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batchnorm            is normal keras bn layer\n",
      "conv1D_e3            f=8 quantized_bits(13,2,0,alpha=1) quantized_bits(13,2,0,alpha=1) \n",
      "qrelu_e3             quantized_relu(13,2,0)\n",
      "conv1D_n1            f=48 quantized_bits(13,2,0,alpha=1) quantized_bits(13,2,0,alpha=1) \n",
      "qrelu_n1             quantized_relu(13,2,0)\n",
      "conv1D_n2            f=48 quantized_bits(13,2,0,alpha=1) quantized_bits(13,2,0,alpha=1) \n",
      "qrelu_n2             quantized_relu(13,2,0)\n",
      "conv1D_n3            f=6 quantized_bits(13,2,0,alpha=1) quantized_bits(13,2,0,alpha=1) \n",
      "qrelu_n3             quantized_relu(13,2,0)\n",
      "q_activation_6       quantized_bits(12,3,0)\n",
      "dense_g1             u=48 quantized_bits(13,2,0,alpha=1) quantized_bits(13,2,0,alpha=1) \n",
      "qrelu_g1             quantized_relu(13,2,0)\n",
      "dense_g2             u=48 quantized_bits(13,2,0,alpha=1) quantized_bits(13,2,0,alpha=1) \n",
      "qrelu_g2             quantized_relu(13,2,0)\n",
      "dense_g3             u=5 quantized_bits(13,2,0,alpha=1) quantized_bits(13,2,0,alpha=1) \n",
      "\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " in_layer (InputLayer)          [(None, 30, 16)]     0           []                               \n",
      "                                                                                                  \n",
      " batchnorm (BatchNormalization)  (None, 30, 16)      64          ['in_layer[0][0]']               \n",
      "                                                                                                  \n",
      " proj_1 (NodeEdgeProjection)    (None, 870, 16)      26100       ['batchnorm[1][0]']              \n",
      "                                                                                                  \n",
      " proj_2 (NodeEdgeProjection)    (None, 870, 16)      26100       ['batchnorm[1][0]']              \n",
      "                                                                                                  \n",
      " concatenate_14 (Concatenate)   (None, 870, 32)      0           ['proj_1[1][0]',                 \n",
      "                                                                  'proj_2[1][0]']                 \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv1D_e3   (None, 870, 8)      522         ['concatenate_14[1][0]']         \n",
      " (PruneLowMagnitude)                                                                              \n",
      "                                                                                                  \n",
      " qrelu_e3 (QActivation)         (None, 870, 8)       0           ['prune_low_magnitude_conv1D_e3[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " proj_3 (NodeEdgeProjection)    (None, 30, 8)        26100       ['qrelu_e3[1][0]']               \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenate)   (None, 30, 24)       0           ['batchnorm[1][0]',              \n",
      "                                                                  'proj_3[1][0]']                 \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv1D_n1   (None, 30, 48)      2354        ['concatenate_15[1][0]']         \n",
      " (PruneLowMagnitude)                                                                              \n",
      "                                                                                                  \n",
      " qrelu_n1 (QActivation)         (None, 30, 48)       0           ['prune_low_magnitude_conv1D_n1[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv1D_n2   (None, 30, 48)      4658        ['qrelu_n1[1][0]']               \n",
      " (PruneLowMagnitude)                                                                              \n",
      "                                                                                                  \n",
      " qrelu_n2 (QActivation)         (None, 30, 48)       0           ['prune_low_magnitude_conv1D_n2[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv1D_n3   (None, 30, 6)       584         ['qrelu_n2[1][0]']               \n",
      " (PruneLowMagnitude)                                                                              \n",
      "                                                                                                  \n",
      " qrelu_n3 (QActivation)         (None, 30, 6)        0           ['prune_low_magnitude_conv1D_n3[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " q_activation_6 (QActivation)   (None, 30, 6)        0           ['qrelu_n3[1][0]']               \n",
      "                                                                                                  \n",
      " pi_gp (GlobalAveragePooling1D)  (None, 6)           0           ['q_activation_6[1][0]']         \n",
      "                                                                                                  \n",
      " prune_low_magnitude_dense_g1 (  (None, 48)          626         ['pi_gp[1][0]']                  \n",
      " PruneLowMagnitude)                                                                               \n",
      "                                                                                                  \n",
      " qrelu_g1 (QActivation)         (None, 48)           0           ['prune_low_magnitude_dense_g1[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dense_g2 (QDense)              (None, 48)           2352        ['qrelu_g1[1][0]']               \n",
      "                                                                                                  \n",
      " qrelu_g2 (QActivation)         (None, 48)           0           ['dense_g2[1][0]']               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_dense_g3 (  (None, 5)           487         ['qrelu_g2[1][0]']               \n",
      " PruneLowMagnitude)                                                                               \n",
      "                                                                                                  \n",
      " softmax_out (Activation)       (None, 5)            0           ['prune_low_magnitude_dense_g3[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 89,947\n",
      "Trainable params: 7,075\n",
      "Non-trainable params: 82,872\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the optimizer ( minimization algorithm )\n",
    "optim = Adam(learning_rate=0.0005)\n",
    "\n",
    "p_en = 1\n",
    "batch = 512\n",
    "p_rate = 0.5\n",
    "if p_en:\n",
    "    import tensorflow_model_optimization as tfmot\n",
    "    from tensorflow_model_optimization.sparsity import keras as sparsity\n",
    "    from tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\n",
    "\n",
    "    NSTEPS = int (( int(len(X_train_val) * 0.3))/batch)\n",
    "\n",
    "    def pruneFunction(layer):\n",
    "        pruning_params = {\n",
    "            'pruning_schedule': sparsity.PolynomialDecay(\n",
    "                initial_sparsity=0.0, final_sparsity=p_rate, begin_step=NSTEPS * 2, end_step=NSTEPS * 10, frequency=NSTEPS\n",
    "            )\n",
    "        }\n",
    "        #pruning_params_mlp_e = {\n",
    "        #    'pruning_schedule': sparsity.PolynomialDecay(\n",
    "        #        initial_sparsity=0.0, final_sparsity=0.5, begin_step=NSTEPS * 2, end_step=NSTEPS * 10, frequency=NSTEPS\n",
    "        #    )\n",
    "        #}\n",
    "        if isinstance(layer, tf.keras.layers.Conv1D): \n",
    "            return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
    "        #if isinstance(layer, tf.keras.layers.Conv1D) and layer.name != 'conv1D_e3':   \n",
    "        #    return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
    "        #if isinstance(layer, tf.keras.layers.Conv1D) and layer.name == 'conv1D_e3':\n",
    "        #    return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params_mlp_e)\n",
    "        if isinstance(layer, tf.keras.layers.Dense) and layer.name != 'dense_out': # exclude output_dense\n",
    "            return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
    "        return layer\n",
    "\n",
    "    print_qmodel_summary(model)\n",
    "    model = tf.keras.models.clone_model(model, clone_function=pruneFunction)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optim, loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\"]\n",
    "    )\n",
    "    \n",
    "    pr = pruning_callbacks.UpdatePruningStep() \n",
    "else:\n",
    "\n",
    "    # Compile the Model\n",
    "    model.compile(\n",
    "        optimizer=optim, loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\"]\n",
    "    )\n",
    "\n",
    "# Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cbd9449c-3cad-42bb-b35a-bf906acf476d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output dir:  prj/nconst30_nbits13_De8_Do6_NL0_SE2_SN2_20240912-200832\n"
     ]
    }
   ],
   "source": [
    "outputdir = \"prj/nconst{}_nbits{}_De{}_Do{}_NL{}_SE{}_SN{}_{}\".format(\n",
    "    nmax,\n",
    "    nbits,\n",
    "    De,\n",
    "    Do,\n",
    "    NL,\n",
    "    scale_e,\n",
    "    scale_n,\n",
    "    time.strftime(\"%Y%m%d-%H%M%S\"),\n",
    ")\n",
    "\n",
    "print(\"output dir: \", outputdir)\n",
    "os.makedirs(outputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e139f56b-eba2-4d64-b925-a806d29de22f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
